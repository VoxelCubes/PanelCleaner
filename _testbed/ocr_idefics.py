# AUTOGENERATED! DO NOT EDIT! File to edit: test_idefics.ipynb.

# %% test_idefics.ipynb 12
from __future__ import annotations

import functools
from pathlib import Path

import pcleaner.ocr.ocr as ocr
import torch
import transformers
from pcleaner.ocr.ocr_tesseract import TesseractOcr
from PIL import Image
from rich.console import Console
from transformers import AutoProcessor
from transformers import Idefics2ForConditionalGeneration
from transformers import PreTrainedModel


# %% auto 0
__all__ = ['IdeficsOCR', 'IdeficsExperimentContext']

# %% test_idefics.ipynb 17
console = Console(width=104, tab_size=4, force_jupyter=True)
cprint = console.print


# %% test_idefics.ipynb 20
from experiments import *
from helpers import *
from ocr_metric import *


# %% test_idefics.ipynb 21
def load_image(img_or_path) -> Image.Image:
    if isinstance(img_or_path, (str, Path)):
        return Image.open(img_or_path)
    elif isinstance(img_or_path, Image.Image):
        return img_or_path
    else:
        raise ValueError(f"img_or_path must be a path or PIL.Image, got: {type(img_or_path)}")


# %% test_idefics.ipynb 36
processor = AutoProcessor.from_pretrained("HuggingFaceM4/idefics2-8b")

# %% test_idefics.ipynb 37
device = "mps" if torch.backends.mps.is_available() else "cuda" if torch.cuda.is_available() else "cpu"

model = Idefics2ForConditionalGeneration.from_pretrained(
        "HuggingFaceM4/idefics2-8b",
        torch_dtype=torch.bfloat16,
        _attn_implementation="flash_attention_2",
        ).to(device)  # type: ignore


# %% test_idefics.ipynb 39
prompt_text_tmpl = (
        "Please perform optical character recognition (OCR) on this image, which displays "
        "speech balloons from a comic book. The text is in {}. Extract the text and "
        "format it as follows: transcribe in standard sentence case, avoid using all capital "
        "letters. Provide the transcribed text clearly and double check the sentence is not all capital letters.")

# prompt_text_tmpl = ("Please perform optical character recognition (OCR) on this image, which displays "
#         f"speech balloons from a manga comic. The text is in {}. Extract the text and "
#         "format it without newlines. Provide the transcribed text clearly.")

# prompt_text_tmpl = ("Please perform optical character recognition (OCR) on this image, which displays "
#         "speech balloons from a comic book. The text is in {}. Extract the text and "
#         "format it as follows: transcribe in standard sentence case (avoid using all capital "
#         "letters) and use asterisks to denote any words that appear in bold within the image. "
#         "Provide the transcribed text clearly.")

# prompt_text_tmpl = ("Please perform optical character recognition (OCR) on this image, which displays "
#         "speech balloons from a comic book. The text is in {}. Extract the text and "
#         "format it as follows: transcribe in standard sentence case, capitalized. Avoid using "
#         "all capital letters. In comics, it is common to use two hyphens '--' to interrupt a sentence. "
#         "Retain any hyphens as they appear in the original text. Provide the transcribed text "
#         "clearly, ensuring it is capitalized where appropriate, including proper nouns.")

prompt_text_tmpl = (
        "Please perform optical character recognition (OCR) on this image, which displays "
        "speech balloons from a comic book. The text is in {}. Extract the text and "
        "format it as follows: transcribe in standard sentence case, capitalized. Avoid using "
        "all capital letters, but ensure it is capitalized where appropriate, including proper nouns. "
        "Provide the transcribed text clearly. Double check the text is not all capital letters.")

default_prompt_text_tmpl = prompt_text_tmpl

# %% test_idefics.ipynb 41
class IdeficsOCR:
    prompt_text_tmpl: str = default_prompt_text_tmpl

    def __init__(self, 
            lang: str | None = None, 
            prompt_text_tmpl: str|None = None, 
            device: str | None = None
        ):
        self.lang = lang
        self.prompt_text_tmpl = prompt_text_tmpl or self.prompt_text_tmpl
        self.device = (device or 
            "mps" if torch.backends.mps.is_available() else "cuda" if torch.cuda.is_available() else "cpu")

    @staticmethod
    def is_idefics_available() -> bool:
        return True

    def _generation_args(self, image: Image.Image, resulting_messages: list[dict]):
        prompt = processor.apply_chat_template(resulting_messages, add_generation_prompt=True)
        inputs = processor(text=prompt, images=[image], return_tensors="pt")
        inputs = {k: v.to(self.device) for k, v in inputs.items()}
        
        max_new_tokens = 512
        repetition_penalty = 1.2
        decoding_strategy = "Greedy"
        temperature = 0.4
        top_p = 0.8

        generation_args = {
            "max_new_tokens": max_new_tokens,
            "repetition_penalty": repetition_penalty,
        }

        assert decoding_strategy in [
            "Greedy",
            "Top P Sampling",
        ]

        if decoding_strategy == "Greedy":
            generation_args["do_sample"] = False
        elif decoding_strategy == "Top P Sampling":
            generation_args["temperature"] = temperature
            generation_args["do_sample"] = True
            generation_args["top_p"] = top_p

        generation_args.update(inputs)
        return prompt, generation_args

    def __call__(
        self,
        img_or_path: Image.Image | Path | str,
        prompt_text: str | None = None,
        lang: str | None = None,
        config: str | None = None,
        show_prompt: bool = False,
        **kwargs,
    ) -> str:
        if not self.is_idefics_available():
            raise RuntimeError("Idefics is not installed or not found.")
        resulting_messages = [
            {
                "role": "user",
                "content": [{"type": "image"}] + [
                    {"type": "text", "text": prompt_text or self.prompt_text_tmpl.format(lang or self.lang)}
                ]
            }
        ]
        image = load_image(img_or_path)
        prompt, generation_args = self._generation_args(image, resulting_messages)
        generated_ids = model.generate(**generation_args)
        generated_texts = processor.batch_decode(
            generated_ids[:, generation_args["input_ids"].size(1):], skip_special_tokens=True)
        if show_prompt:
            cprint("INPUT:", prompt, "|OUTPUT:", generated_texts)
        return generated_texts[0]#.strip('"')

    def postprocess_ocr(self, text):
        return ' '.join(remove_multiple_whitespaces(text).splitlines())


# %% test_idefics.ipynb 43
class IdeficsExperimentContext(OCRExperimentContext):
    @functools.lru_cache()
    def mocr(self, ocr_model: str, lang: str):
        if ocr_model == 'Idefics':
            proc = IdeficsOCR(lang)
        else:
            engine = self.engines[ocr_model]
            ocr_processor = ocr.get_ocr_processor(True, engine)
            proc = ocr_processor[lang2pcleaner(lang)]
            if isinstance(proc, TesseractOcr):
                proc.lang = lang2tesseract(lang)
        return proc

